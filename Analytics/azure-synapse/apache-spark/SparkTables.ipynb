{
  "nbformat": 4,
  "nbformat_minor": 2,
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "metadata": {
        "microsoft": {
          "language": "python"
        },
        "collapsed": false
      },
      "source": [
        "%%pyspark\r\n",
        "from pyspark.sql.types import *\r\n",
        "from pyspark.sql.functions import *\r\n",
        "\r\n",
        "orderSchema = StructType([\r\n",
        "    StructField(\"PurchaseOrderID\", IntegerType()),\r\n",
        "    StructField(\"PurchaseOrderDetailID\", IntegerType()),\r\n",
        "    StructField(\"DueDate\", DateType()),\r\n",
        "    StructField(\"OrderQty\", IntegerType()),\r\n",
        "    StructField(\"ProductID\", IntegerType()),\r\n",
        "    StructField(\"UnitPrice\", DecimalType(12,2)),\r\n",
        "    StructField(\"LineTotal\", DecimalType(12,2)),\r\n",
        "    StructField(\"ReceivedQty\", DecimalType(12,2)),\r\n",
        "    StructField(\"RejectedQty\", DecimalType(12,2)),\r\n",
        "    StructField(\"StockedQty\", DecimalType(12,2)),\r\n",
        "    StructField(\"ModifiedDate\", DateType())\r\n",
        "    ])\r\n",
        "\r\n",
        "csvDF = spark.read.load('abfss://root@adlesilabs.dfs.core.windows.net/demofiles/csv/PurchaseOrderDetail.csv'\r\n",
        "             ,format='csv'\r\n",
        "             ,schema=orderSchema\r\n",
        "             ,header=True\r\n",
        ")\r\n",
        "display(csvDF.limit(3))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "## Two types of tables\r\n",
        "- Managed Tables (Internal)\r\n",
        "- Unmanaged Tables (External)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "```\r\n",
        " \r\n",
        "```\r\n",
        "## Managed (or Internal) Tables\r\n",
        "- Spark manages both the data and the metadata.\r\n",
        "- Data is saved in the Spark SQL warehouse directory that is the default for managed tables - \r\n",
        "- Whereas metadata is saved in a meta-store of relational entities (including databases, tables, temporary views) and can be accessed through an interface known as the “catalog”.\r\n",
        "- if you delete a managed table, Spark will delete both the table data in the warehouse and the metadata in the meta-store"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "# No need to mention the file path directoru name\r\n",
        "DeltaTableName = \"PurchaseOrderDetail_dp203\"\r\n",
        "\r\n",
        "# Save as a Delta files\r\n",
        "(\r\n",
        "    csvDF.write.format(\"parquet\")\r\n",
        "         .mode(\"overwrite\")\r\n",
        "         .option(\"overwriteSchema\", \"true\")\r\n",
        "         .saveAsTable(DeltaTableName)\r\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "spark.catalog.listTables()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "microsoft": {
          "language": "sparksql"
        },
        "collapsed": false
      },
      "source": [
        "%%sql\r\n",
        "DESCRIBE  PurchaseOrderDetail_dp203"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "microsoft": {
          "language": "sparksql"
        },
        "collapsed": false
      },
      "source": [
        "%%sql\r\n",
        "\r\n",
        "SELECT *\r\n",
        "FROM PurchaseOrderDetail_dp203 \r\n",
        "LIMIT 3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "microsoft": {
          "language": "sparksql"
        },
        "collapsed": false
      },
      "source": [
        "%%sql\r\n",
        "SELECT *\r\n",
        "FROM PurchaseOrderDetail_SQL\r\n",
        "LIMIT 5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "microsoft": {
          "language": "sparksql"
        },
        "collapsed": false
      },
      "source": [
        "%%sql\r\n",
        "DROP TABLE PurchaseOrderDetail_dp203;"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "spark.catalog.listTables()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "```\r\n",
        " \r\n",
        "```\r\n",
        "## Unmanaged (or External) Tables: \r\n",
        "- Spark only manages the metadatabut not the data\r\n",
        "- Requires you to specify the exact location where you wish to save the table.\r\n",
        "- if you delete an unmanaged table, Spark will just delete the metadata without deleting the data\r\n",
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "microsoft": {
          "language": "python"
        }
      },
      "source": [
        "%%pyspark\r\n",
        "# Example: Managed Table (External)\r\n",
        "\r\n",
        "\r\n",
        "deltaTablePath = \"abfss://root@adlesilabs.dfs.core.windows.net/lakedb/sparktable/PurchaseOrderDetail_dp203_umt\"\r\n",
        "\r\n",
        "DeltaTableName = \"PurchaseOrderDetail_dp203_umt\"\r\n",
        "# Save as a Parquet files\r\n",
        "(\r\n",
        "    csvDF.write.format(\"parquet\")\r\n",
        "         .mode(\"overwrite\")\r\n",
        "         .option(\"overwriteSchema\", \"true\")\r\n",
        "         .option(\"path\", deltaTablePath)\r\n",
        "         .saveAsTable(DeltaTableName)\r\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "spark.catalog.listTables()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "microsoft": {
          "language": "sparksql"
        },
        "collapsed": false
      },
      "source": [
        "%%sql\r\n",
        "DESCRIBE  PurchaseOrderDetail_dp203_umt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "microsoft": {
          "language": "sparksql"
        },
        "collapsed": false
      },
      "source": [
        "%%sql\r\n",
        "\r\n",
        "SELECT *\r\n",
        "FROM PurchaseOrderDetail_dp203_umt \r\n",
        "LIMIT 3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "microsoft": {
          "language": "sparksql"
        },
        "collapsed": false
      },
      "source": [
        "%%sql\r\n",
        "DROP TABLE PurchaseOrderDetail_dp203_umt;"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "spark.catalog.listTables()"
      ]
    }
  ],
  "metadata": {
    "description": null,
    "save_output": true,
    "kernelspec": {
      "name": "synapse_pyspark",
      "display_name": "Synapse PySpark"
    },
    "language_info": {
      "name": "python"
    }
  }
}