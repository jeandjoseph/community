{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sending request to Azure OpenAI API Using Python SDK \n",
    "\n",
    "In the below example are **important parameters**, more parameters are added to openai.ChatCompletion.create() to generate a response. Here’s what each means:\n",
    "- The **engine** parameter specifies which language model to use (“gpt-35-turbo” is the most powerful GPT-3 model at the time of writing)\n",
    "- The **messages** parameter is the text prompt to generate a response to\n",
    "- The **max_tokens** parameter sets the maximum number of tokens (words) that the model should generate\n",
    "- The **temperature** parameter controls the level of randomness in the generated text\n",
    "- The **stop** parameter can be used to specify one or more strings that should be used to indicate the end of the generated text\n",
    "- If you want to generate multiple responses, you can set **n** to the number of responses you want returned\n",
    "- The **strip()** method removes any leading and trailing spaces from the text."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting up the environment variables for Azure OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, openai\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "# Set OpenAI configuration settings values\n",
    "azure_openai_api_type        = os.environ[\"OPENAI_API_TYPE\"]\n",
    "azure_azure_openeai_key      = os.environ[\"OPENAI_API_KEY\"]\n",
    "azure_azur_openeai_endpoint  = os.environ[\"OPENAI_API_BASE\"]\n",
    "azure_openai_api_version     = os.environ[\"OPENAI_API_VERSION\"]\n",
    "azure_openai_api_model       = os.environ[\"OPENAI_API_MODEL\"]\n",
    "\n",
    "# Temperature & Tokens\n",
    "azure_openai_api_temperature = 0.7\n",
    "azure_openai_api_max_tokens  = 125"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_input = f\"\"\"\n",
    "What is powerbi?\n",
    "\"\"\"\n",
    "\n",
    "messages=[\n",
    "    {\n",
    "        \"role\": \"user\", \"content\": user_input\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sending request for summary to Azure OpenAI endpoint...\n",
      "\n",
      "\n",
      "{\n",
      "  \"id\": \"chatcmpl-8JgdEQkpGwvMNLAgxhqX3XVBQYuYc\",\n",
      "  \"object\": \"chat.completion\",\n",
      "  \"created\": 1699702800,\n",
      "  \"model\": \"gpt-35-turbo\",\n",
      "  \"prompt_filter_results\": [\n",
      "    {\n",
      "      \"prompt_index\": 0,\n",
      "      \"content_filter_results\": {\n",
      "        \"hate\": {\n",
      "          \"filtered\": false,\n",
      "          \"severity\": \"safe\"\n",
      "        },\n",
      "        \"self_harm\": {\n",
      "          \"filtered\": false,\n",
      "          \"severity\": \"safe\"\n",
      "        },\n",
      "        \"sexual\": {\n",
      "          \"filtered\": false,\n",
      "          \"severity\": \"safe\"\n",
      "        },\n",
      "        \"violence\": {\n",
      "          \"filtered\": false,\n",
      "          \"severity\": \"safe\"\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ],\n",
      "  \"choices\": [\n",
      "    {\n",
      "      \"index\": 0,\n",
      "      \"finish_reason\": \"stop\",\n",
      "      \"message\": {\n",
      "        \"role\": \"assistant\",\n",
      "        \"content\": \"Power BI is a business analytics tool developed by Microsoft. It provides interactive visualizations and business intelligence capabilities with an interface that is easy to use for end-users to create their own reports and dashboards. Power BI allows users to connect to multiple data sources, transform and clean the data, and create visually appealing reports and dashboards. It also offers features like data modeling, real-time analytics, and collaboration capabilities for team members to work together on data analysis and reporting. Power BI can be used on both desktop and mobile platforms, making it accessible for users across different devices.\"\n",
      "      },\n",
      "      \"content_filter_results\": {\n",
      "        \"hate\": {\n",
      "          \"filtered\": false,\n",
      "          \"severity\": \"safe\"\n",
      "        },\n",
      "        \"self_harm\": {\n",
      "          \"filtered\": false,\n",
      "          \"severity\": \"safe\"\n",
      "        },\n",
      "        \"sexual\": {\n",
      "          \"filtered\": false,\n",
      "          \"severity\": \"safe\"\n",
      "        },\n",
      "        \"violence\": {\n",
      "          \"filtered\": false,\n",
      "          \"severity\": \"safe\"\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ],\n",
      "  \"usage\": {\n",
      "    \"prompt_tokens\": 13,\n",
      "    \"completion_tokens\": 114,\n",
      "    \"total_tokens\": 127\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "openai.api_type = azure_openai_api_type\n",
    "openai.api_base = azure_azur_openeai_endpoint\n",
    "openai.api_version = azure_openai_api_version\n",
    "openai.api_key = azure_azure_openeai_key\n",
    "# Send request to Azure OpenAI model\n",
    "print(\"Sending request for summary to Azure OpenAI endpoint...\\n\\n\")\n",
    "response = openai.ChatCompletion.create(\n",
    "    engine=azure_openai_api_model,\n",
    "    temperature = azure_openai_api_temperature,\n",
    "    max_tokens  = azure_openai_api_max_tokens,\n",
    "    messages    = messages\n",
    ")\n",
    "output = []\n",
    "output = response\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"prompt_tokens\": 13,\n",
      "  \"completion_tokens\": 114,\n",
      "  \"total_tokens\": 127\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(response.usage)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting number of tokens from the text (prompts)\n",
    "- Manual or one time excercise\n",
    "    - [Tokenizer](https://platform.openai.com/tokenizer)\n",
    "- Programatically handle number of tokens\n",
    "    - https://github.com/openai/tiktoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tiktoken in c:\\program files\\python311\\lib\\site-packages (0.5.1)\n",
      "Requirement already satisfied: regex>=2022.1.18 in c:\\program files\\python311\\lib\\site-packages (from tiktoken) (2023.10.3)\n",
      "Requirement already satisfied: requests>=2.26.0 in c:\\program files\\python311\\lib\\site-packages (from tiktoken) (2.31.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\program files\\python311\\lib\\site-packages (from requests>=2.26.0->tiktoken) (3.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\program files\\python311\\lib\\site-packages (from requests>=2.26.0->tiktoken) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\program files\\python311\\lib\\site-packages (from requests>=2.26.0->tiktoken) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\program files\\python311\\lib\\site-packages (from requests>=2.26.0->tiktoken) (2023.5.7)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.1.2 -> 23.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install tiktoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tiktoken\n",
    "\n",
    "# Ref: https://learn.microsoft.com/en-us/answers/questions/1193969/how-to-integrate-tiktoken-library-with-azure-opena\n",
    "def num_tokens_from_messages(messages, model):\n",
    "    encoding = tiktoken.encoding_for_model(model)\n",
    "    num_tokens = 0\n",
    "    for message in messages:\n",
    "        num_tokens += 4  # every message follows <im_start>{role/name}\\n{content}<im_end>\\n\n",
    "        for key, value in message.items():\n",
    "            num_tokens += len(encoding.encode(value))\n",
    "            if key == \"name\":  # if there's a name, the role is omitted\n",
    "                num_tokens += -1  # role is always required and always 1 token\n",
    "    num_tokens += 2  # every reply is primed with <im_start>assistant\n",
    "    return num_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_tokens_from_messages(messages, model=azure_openai_api_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Here are some rules of thumb for understanding tokens in terms of lengths:](https://help.openai.com/en/articles/4936856-what-are-tokens-and-how-to-count-them)\n",
    "- 1 token ~= 4 chars in English\n",
    "- 1 token ~= ¾ words\n",
    "- 100 tokens ~= 75 words\n",
    "- 1-2 sentence ~= 30 tokens\n",
    "- 1 paragraph ~= 100 tokens\n",
    "- 1,500 words ~= 2048 tokens\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To manage tokens effectively in OpenAI, here are some suggestions:\n",
    "\n",
    "- [Understand your token usage: Knowing how many tokens your prompts and completions typically use can help you manage your usage more effectively. You can use OpenAI’s interactive Tokenizer tool to calculate the number of tokens and see how text is broken into tokens.](https://help.openai.com/en/articles/4936856-what-are-tokens-and-how-to-count-them)\n",
    "- [Use shorter prompts: If you’re hitting token limits, consider using shorter prompts.](https://platform.openai.com/docs/guides/production-best-practices/improving-latencies)\n",
    "- [Break text into smaller pieces: If your text is too long to fit within the token limit, you might need to break it down into smaller pieces.](https://help.openai.com/en/articles/4936856-what-are-tokens-and-how-to-count-them)\n",
    "- [Cache common queries: If you find that you’re frequently processing the same queries, consider caching these so they don’t need to be processed repeatedly.](https://platform.openai.com/docs/guides/production-best-practices/api-keys)\n",
    "- Set a monthly budget: You can set a monthly budget in your billing settings, after which OpenAI will stop serving your requests3.[azure openai](https://azure.microsoft.com/en-us/pricing/details/cognitive-services/openai-service/), [openai](https://openai.com/pricing)\n",
    "- Remember, the number of tokens used in an API call affects the cost, as usage is priced by token1. So, effective token management can also help control costs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extra\n",
    "- [Summary of the tokenizers](https://huggingface.co/docs/transformers/tokenizer_summary)\n",
    "- [Subword Tokenization - Handling Misspellings and Multilingual Data](https://www.thoughtvector.io/blog/subword-tokenization/)\n",
    "- [Subword tokenizers](https://www.tensorflow.org/text/guide/subwords_tokenizer)\n",
    "- **Tokenizers words cons**\n",
    "    - Big vocabularies can be complicated and even can error out such as out-of-vocabulary words\n",
    "- **Tokenizers Characters cons**\n",
    "    - Loss of context within words and much longer sequences for a given input\n",
    "- **Tokenizers Sub-words cons**\n",
    "    - \"Smart\" vocabulary built from characters which co-occur frequently\n",
    "    - more robust to novel words"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
