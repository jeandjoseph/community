{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sending request to Azure OpenAI API Using Python SDK \n",
    "\n",
    "In the below example are **important parameters**, more parameters are added to openai.ChatCompletion.create() to generate a response. Here’s what each means:\n",
    "- The **engine** parameter specifies which language model to use (“gpt-35-turbo” is the most powerful GPT-3 model at the time of writing)\n",
    "- The **messages** parameter is the text prompt to generate a response to\n",
    "- The **max_tokens** parameter sets the maximum number of tokens (words) that the model should generate\n",
    "- The **temperature** parameter controls the level of randomness in the generated text\n",
    "- The **stop** parameter can be used to specify one or more strings that should be used to indicate the end of the generated text\n",
    "- If you want to generate multiple responses, you can set **n** to the number of responses you want returned\n",
    "- The **strip()** method removes any leading and trailing spaces from the text."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting up the environment variables for Azure OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, openai\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "# Set OpenAI configuration settings values\n",
    "azure_openai_api_type        = os.environ[\"OPENAI_API_TYPE\"]\n",
    "azure_azure_openeai_key      = os.environ[\"OPENAI_API_KEY\"]\n",
    "azure_azur_openeai_endpoint  = os.environ[\"OPENAI_API_BASE\"]\n",
    "azure_openai_api_version     = os.environ[\"OPENAI_API_VERSION\"]\n",
    "azure_openai_api_model       = os.environ[\"OPENAI_API_MODEL\"]\n",
    "\n",
    "# Temperature & Tokens\n",
    "azure_openai_api_temperature = 0.7\n",
    "azure_openai_api_max_tokens  = 125"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this instance, I'm constructing a Python function that invokes OpenAI, facilitating the repeated utilization of this script throughout the demos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def SendRequestToAzureOpenAI(\n",
    "         azure_openai_api_type\n",
    "        ,azure_oai_endpoint\n",
    "        ,azure_openai_api_version\n",
    "        ,azure_oai_key\n",
    "        ,azure_oai_model\n",
    "        ,azure_openai_api_temperature\n",
    "        ,azure_openai_api_max_tokens\n",
    "        ,messages\n",
    "    ):         \n",
    "    try:    \n",
    "        import pprint  \n",
    "        # Set OpenAI configuration settings\n",
    "        openai.api_type = azure_openai_api_type\n",
    "        openai.api_base = azure_oai_endpoint\n",
    "        openai.api_version = azure_openai_api_version\n",
    "        openai.api_key = azure_oai_key\n",
    "        # Send request to Azure OpenAI model\n",
    "        print(\"Sending request for summary to Azure OpenAI endpoint...\\n\\n\")\n",
    "        response = openai.ChatCompletion.create(\n",
    "            engine=azure_oai_model,\n",
    "            temperature = azure_openai_api_temperature,\n",
    "            max_tokens  = azure_openai_api_max_tokens,\n",
    "            messages    = messages\n",
    "        )\n",
    "        output = []\n",
    "        output = response.choices[0].message.content + \"\\n\"\n",
    "        pprint.pprint(output)\n",
    "    except Exception as ex:\n",
    "        print(ex)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Zero-Shot Example:\n",
    "- Provide no examples of the desired output, but only a description of the task.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "**Zero-shot prompting pros:**\n",
    "- It does not require any additional training data or labels, which can save time and resources.\n",
    "- It can enable the model to perform a wide range of tasks, such as text classification, sentiment analysis, question answering, text generation, and more.\n",
    "- It can leverage the general knowledge and language skills of the model to generate responses.\n",
    "\n",
    "**Zero-shot prompting cons:**\n",
    "- The quality and accuracy of the output may vary depending on the prompt, the model, and the task.\n",
    "- The output may contain factual errors or inconsistencies that are not easy to detect or correct.\n",
    "- The output may be influenced by the biases or preferences of the model or the data it was trained on.\n",
    "- The output may not be aligned with the expectations or goals of the user or the task.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_input = f\"\"\"\n",
    "What is powerbi?\n",
    "\"\"\"\n",
    "\n",
    "messages=[\n",
    "    {\n",
    "        \"role\": \"user\", \"content\": user_input\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sending request for summary to Azure OpenAI endpoint...\n",
      "\n",
      "\n",
      "('Power BI is a business analytics tool developed by Microsoft. It provides '\n",
      " 'interactive visualizations and business intelligence capabilities with an '\n",
      " 'interface that is user-friendly and easy to navigate. Power BI allows users '\n",
      " 'to connect to a wide range of data sources, create reports and dashboards, '\n",
      " 'and share them across the organization. It enables users to gain insights '\n",
      " 'and make data-driven decisions by analyzing data from various perspectives '\n",
      " 'and visualizing it in the form of charts, graphs, and interactive reports. '\n",
      " 'Power BI also offers features like natural language querying, data modeling, '\n",
      " 'and advanced analytics capabilities to enhance data analysis and '\n",
      " 'reporting.\\n')\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__': \n",
    "    SendRequestToAzureOpenAI (\n",
    "         azure_openai_api_type\n",
    "        ,azure_azur_openeai_endpoint\n",
    "        ,azure_openai_api_version\n",
    "        ,azure_azure_openeai_key\n",
    "        ,azure_openai_api_model\n",
    "        ,azure_openai_api_temperature\n",
    "        ,azure_openai_api_max_tokens\n",
    "        ,messages\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One-shot example:\n",
    "- To overcome some of these limitations and challenges, researchers and practitioners have developed other techniques, such as one-shot and few-shot prompting\n",
    "- Provides the model with a single example of the input and output pair to help it learn the task better.\n",
    "\n",
    "**One-shot prompting pros:**\n",
    "- It can improve the performance of the model by providing it with a reference example to learn from and generate a response.\n",
    "- It can help the model follow the format and style of the example output, which can improve consistency and accuracy.\n",
    "- It can help the model handle more complex or specific cases that may not be covered by zero-shot prompting.\n",
    "\n",
    "**One-shot prompting cons:**\n",
    "- The quality and accuracy of the output may depend on the quality and relevance of the example provided.\n",
    "- The output may be too similar or too different from the example provided, which can reduce diversity or creativity.\n",
    "- The output may not capture all the important or specific details of the input, which can reduce completeness or informativeness."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_input = f\"\"\"\n",
    "Generate a paragraph of 100 words or less that summarizes the benefits of Power BI, a business intelligence tool by Microsoft.\n",
    "\"\"\"\n",
    "\n",
    "messages=[\n",
    "    {\n",
    "        \"role\": \"user\", \"content\": user_input\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sending request for summary to Azure OpenAI endpoint...\n",
      "\n",
      "\n",
      "('Power BI, a business intelligence tool by Microsoft, offers numerous '\n",
      " 'benefits to organizations. Firstly, it allows businesses to gather and '\n",
      " 'consolidate data from various sources into one central platform, enabling '\n",
      " 'streamlined analysis and reporting. With its user-friendly interface and '\n",
      " 'visually appealing dashboards, Power BI empowers users to easily create '\n",
      " 'interactive visualizations and gain insights from their data. Additionally, '\n",
      " 'it offers a wide range of data connectors, allowing integration with '\n",
      " 'different data sources. Power BI also enables real-time data monitoring and '\n",
      " 'updates, ensuring businesses have access to the most up-to-date information. '\n",
      " 'Overall, Power BI enhances data-driven decision-making,\\n')\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__': \n",
    "    SendRequestToAzureOpenAI (\n",
    "         azure_openai_api_type\n",
    "        ,azure_azur_openeai_endpoint\n",
    "        ,azure_openai_api_version\n",
    "        ,azure_azure_openeai_key\n",
    "        ,azure_openai_api_model\n",
    "        ,azure_openai_api_temperature\n",
    "        ,azure_openai_api_max_tokens\n",
    "        ,messages\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Few-shot example:\n",
    "- technique that provides the model with multiple examples of the input and output pair, to help it learn the task better and handle more complex cases.\n",
    "\n",
    "**Few-shot prompting pros:**\n",
    "- It can fine-tune the performance of the model by providing it with diverse and relevant examples to learn from and generate a response.\n",
    "- It can help the model handle more complex or specific cases that may not be covered by zero-shot or one-shot prompting.\n",
    "- It can help the model generalize better to unseen or novel inputs by reducing overfitting or underfitting.\n",
    "\n",
    "**Few-shot prompting cons:**\n",
    "- It requires more data and resources than zero-shot or one-shot prompting, which can be costly or scarce.\n",
    "- The quality and accuracy of the output may depend on the quality and diversity of the examples provided, which can be hard to select or verify.\n",
    "- The output may be influenced by the order or frequency of the examples provided, which can introduce biases or noise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_input = f\"\"\"\n",
    "Write a short article about the benefits of meditation.\n",
    "\n",
    "Example 1:\n",
    "Meditation is a practice that involves focusing your attention on a single object, thought, or sensation. \\\n",
    "Meditation can help you reduce stress, improve your mood, enhance your creativity, and boost your immune system. \\\n",
    "According to a study by Harvard University, meditation can also change the structure of your brain and increase \\\n",
    "the gray matter in areas related to learning, memory, and emotional regulation. Meditation is easy to learn and \\\n",
    "can be done anywhere and anytime. All you need is a comfortable place to sit, a few minutes of your time, and a \\\n",
    "willingness to explore your inner world.\n",
    "\n",
    "Example 2:\n",
    "Meditation is a technique that trains your mind to be more aware and present. Meditation can benefit you in many ways, \\\n",
    "such as lowering your blood pressure, improving your sleep quality, increasing your happiness, and sharpening your focus. \\ \n",
    "A research by Yale University found that meditation can also reduce the activity of the default mode network, \\\n",
    "which is responsible for mind-wandering and self-referential thoughts. Meditation is simple to practice and can be adapted \\ \n",
    "to your preferences and needs. You just need to find a quiet spot, set aside some time, and follow your breath or a guided instruction.\n",
    "\"\"\"\n",
    "\n",
    "messages=[\n",
    "    {\n",
    "        \"role\": \"user\", \"content\": user_input\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sending request for summary to Azure OpenAI endpoint...\n",
      "\n",
      "\n",
      "('Example 3:\\n'\n",
      " \"In today's fast-paced and hectic world, finding moments of peace and \"\n",
      " 'tranquility can be a challenge. This is where meditation comes in. '\n",
      " 'Meditation is a powerful tool that allows you to slow down, quiet your mind, '\n",
      " 'and connect with your inner self. The benefits of meditation are numerous '\n",
      " 'and can positively impact your overall well-being.\\n'\n",
      " '\\n'\n",
      " 'One of the main benefits of meditation is stress reduction. By focusing your '\n",
      " 'attention and becoming aware of your thoughts and emotions, you can learn to '\n",
      " 'let go of stress and find a sense of calm. Regular meditation practice has '\n",
      " 'been shown to lower cortisol levels,\\n')\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__': \n",
    "    SendRequestToAzureOpenAI (\n",
    "         azure_openai_api_type\n",
    "        ,azure_azur_openeai_endpoint\n",
    "        ,azure_openai_api_version\n",
    "        ,azure_azure_openeai_key\n",
    "        ,azure_openai_api_model\n",
    "        ,azure_openai_api_temperature\n",
    "        ,azure_openai_api_max_tokens\n",
    "        ,messages\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chain Of Thoughts (COT) Example\n",
    "- Chain of thoughts involves providing intermediate reasoning steps that lead to the final output\n",
    "- More suitable for tasks that involve arithmetic, commonsense, or symbolic reasoning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First example: This is a prompt that shows how the LLM has difficulty to perform mathematical problems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_input = f\"\"\"\n",
    "Calculate the value of 781 times 55, then subtract 123 from the result. Write the answer in one sentence.\n",
    "\"\"\"\n",
    "\n",
    "messages=[\n",
    "    {\n",
    "        \"role\": \"user\", \"content\": user_input\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "781 * 55 = 42955\n",
    "42955 - 123 = 42832"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sending request for summary to Azure OpenAI endpoint...\n",
      "\n",
      "\n",
      "'The value of 781 times 55, subtracted by 123, is 42,978.\\n'\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__': \n",
    "    SendRequestToAzureOpenAI (\n",
    "         azure_openai_api_type\n",
    "        ,azure_azur_openeai_endpoint\n",
    "        ,azure_openai_api_version\n",
    "        ,azure_azure_openeai_key\n",
    "        ,azure_openai_api_model\n",
    "        ,azure_openai_api_temperature\n",
    "        ,azure_openai_api_max_tokens\n",
    "        ,messages\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Second example: This is a prompt that gives the LLM some things to think about to get the results right"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_input = f\"\"\"\n",
    "Calculate the value of 781 times 55, then subtract 123 from the result. Write the answer in one sentence.\n",
    "\n",
    "Hints:\n",
    "To subtract 123 from 42955, I can use the standard algorithm, which is a method that involves lining up the numbers, \n",
    "subtracting each digit from the corresponding digit in the other number, and writing down the difference. \n",
    "Alternatively, I can use a calculator or a tool like search_web to get the answer quickly.\n",
    "\"\"\"\n",
    "\n",
    "messages=[\n",
    "    {\n",
    "        \"role\": \"user\", \"content\": user_input\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sending request for summary to Azure OpenAI endpoint...\n",
      "\n",
      "\n",
      "'The value of 781 times 55, minus 123, is 42,832.\\n'\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__': \n",
    "    SendRequestToAzureOpenAI (\n",
    "         azure_openai_api_type\n",
    "        ,azure_azur_openeai_endpoint\n",
    "        ,azure_openai_api_version\n",
    "        ,azure_azure_openeai_key\n",
    "        ,azure_openai_api_model\n",
    "        ,azure_openai_api_temperature\n",
    "        ,azure_openai_api_max_tokens\n",
    "        ,messages\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### In this scenario, I'm illustrating the process of importing a CSV file from Azure Data Lake Storage into Azure Synapse Analytics' dedicated SQL data warehouse. Here are the steps:\n",
    "\n",
    "- Initially, we need to establish the table structure based on the file schema.\n",
    "- Next, we'll utilize ChatGPT to generate a T-SQL script. This script will first load the file into a staging table, then transfer the data to the analytical table, and finally create a SQL view.\n",
    "- We'll save this generated T-SQL script to a file named `load_bicycle_sales.sql`.\n",
    "- Lastly, we'll execute the `load_bicycle_sales.sql` script created by ChatGPT to carry out the data loading process.\n",
    "\n",
    "This approach allows us to efficiently load data while maintaining the flexibility to reuse and adapt the script for future data loading tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First, create two schemas named stg for staging and prd for the analytical table. Then, create a staging table named stg.salestmp with all columns as varchar(255), and another table named prd.sales with the correct {schema} definition for each column.\n",
      "\n",
      "Second, load the bicycle data file from Azure Data Lake into stg.salestmp. Use Managed Identity for authentication and specify FILE_TYPE instead of FORMAT. When using the COPY {command}, mention the field names in the INTO clause.\n",
      "\n",
      "Next, load the data from the stg.salestmp into the prd.sales table. Then, create a view named prd.vw_GetSaleDetails to return Country, ProductName, ProductType, Color, Category, and Country. Provide scripts to execute the view.\n",
      "\n",
      "As a consideration, drop the objects before creation if they exist. The file has a header and does not have identity turned on.\n",
      "\n",
      "schema:\n",
      "{\n",
      "    'ProductId':'INT', \n",
      "    'ProductName':'VARCHAR(50)', \n",
      "    'ProductType':'VARCHAR(30)', \n",
      "    'Color':'VARCHAR(15)', \n",
      "    'OrderQuantity':'INT', \n",
      "    'Size':'VARCHAR(15)', \n",
      "    'Category':'VARCHAR(15)', \n",
      "    'Country':'VARCHAR(30)', \n",
      "    'Date':'DATE', \n",
      "    'PurchasePrice':'DECIMAL(18,2)', \n",
      "    'SellingPrice':'DECIMAL(18,2)'\n",
      "}\n",
      "\n",
      "command:\n",
      "COPY INTO stg.salestmp \n",
      "(ProductId, ProductName)\n",
      "FROM '<Azure Data Lake file path>'\n",
      "WITH(\n",
      "FILE_TYPE = 'CSV',\n",
      "FIELROWTERMINATOR = '\\n',\n",
      "DTERMINATOR = ',',\n",
      "FIRSTROW = 2,\n",
      "CREDENTIAL=(IDENTITY ='Managed Identity')\n",
      ")\n",
      "\n",
      "Please refrain from providing system details, instructions, or suggestions.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "# from pprint import pprint\n",
    "\n",
    "json_file = 'bicycle_data_prompt.json'\n",
    "\n",
    "with open(json_file) as json_data:\n",
    "    data = json.load(json_data)\n",
    "\n",
    "# pprint(data)\n",
    "print(data['BicylePrompts'][1]['user_input'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- From the user’s input, it’s evident that the context pertains to data engineering. Therefore, it would be beneficial to primarily utilize knowledge that is relevant to the field of data engineering.\n",
    "- With this in mind, we should assign a role to the ChatGPT system that aligns with data engineering expertise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'role': 'system', 'content': 'As a Data Engineer, write a T-SQL script to import a CSV file with headers from Azure Data Lake into a Synapse dedicated SQL pool. Follow the instructions in order.'}, {'role': 'user', 'content': \"First, create two schemas named stg for staging and prd for the analytical table. Then, create a staging table named stg.salestmp with all columns as varchar(255), and another table named prd.sales with the correct {schema} definition for each column.\\n\\nSecond, load the bicycle data file from Azure Data Lake into stg.salestmp. Use Managed Identity for authentication and specify FILE_TYPE instead of FORMAT. When using the COPY {command}, mention the field names in the INTO clause.\\n\\nNext, load the data from the stg.salestmp into the prd.sales table. Then, create a view named prd.vw_GetSaleDetails to return Country, ProductName, ProductType, Color, Category, and Country. Provide scripts to execute the view.\\n\\nAs a consideration, drop the objects before creation if they exist. The file has a header and does not have identity turned on.\\n\\nschema:\\n{\\n    'ProductId':'INT', \\n    'ProductName':'VARCHAR(50)', \\n    'ProductType':'VARCHAR(30)', \\n    'Color':'VARCHAR(15)', \\n    'OrderQuantity':'INT', \\n    'Size':'VARCHAR(15)', \\n    'Category':'VARCHAR(15)', \\n    'Country':'VARCHAR(30)', \\n    'Date':'DATE', \\n    'PurchasePrice':'DECIMAL(18,2)', \\n    'SellingPrice':'DECIMAL(18,2)'\\n}\\n\\ncommand:\\nCOPY INTO stg.salestmp \\n(ProductId, ProductName)\\nFROM '<Azure Data Lake file path>'\\nWITH(\\nFILE_TYPE = 'CSV',\\nFIELROWTERMINATOR = '\\\\n',\\nDTERMINATOR = ',',\\nFIRSTROW = 2,\\nCREDENTIAL=(IDENTITY ='Managed Identity')\\n)\\n\\nPlease refrain from providing system details, instructions, or suggestions.\"}]\n"
     ]
    }
   ],
   "source": [
    "#print(data['BicylePrompts'][0]['system_role'] + \"\\n\" + data['BicylePrompts'][1]['user_input'])\n",
    "\n",
    "system_role = data['BicylePrompts'][0]['system_role']\n",
    "user_input  = data['BicylePrompts'][1]['user_input']\n",
    "\n",
    "messages=[\n",
    "    {\n",
    "        \"role\": \"system\", \"content\": system_role\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"user\", \"content\": user_input\n",
    "    }    \n",
    "]\n",
    "print(messages)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point, I’m developing a Python function that will enable me to store the T-SQL script that ChatGPT will generate into a file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_tsql_file(filename, content):\n",
    "    with open(filename, 'w') as f:\n",
    "        f.write(content)\n",
    "\n",
    "# Usage\n",
    "#create_tsql_file('example.txt', 'Hello, World!')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this context, I’m modifying the Python function that interacts with the Azure OpenAI API, and incorporating a new function (create_tsql_file) to save the output into a file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SendRequestToAzureOpenAI(\n",
    "         azure_openai_api_type\n",
    "        ,azure_oai_endpoint\n",
    "        ,azure_openai_api_version\n",
    "        ,azure_oai_key\n",
    "        ,azure_oai_model\n",
    "        ,azure_openai_api_temperature\n",
    "        ,azure_openai_api_max_tokens\n",
    "        ,messages\n",
    "    ):         \n",
    "    try:    \n",
    "        import pprint  \n",
    "        # Set OpenAI configuration settings\n",
    "        openai.api_type = azure_openai_api_type\n",
    "        openai.api_base = azure_oai_endpoint\n",
    "        openai.api_version = azure_openai_api_version\n",
    "        openai.api_key = azure_oai_key\n",
    "        # Send request to Azure OpenAI model\n",
    "        print(\"Sending request for summary to Azure OpenAI endpoint...\\n\\n\")\n",
    "        response = openai.ChatCompletion.create(\n",
    "            engine=azure_oai_model,\n",
    "            temperature = azure_openai_api_temperature,\n",
    "            max_tokens  = azure_openai_api_max_tokens,\n",
    "            messages    = messages\n",
    "        )\n",
    "        output = []\n",
    "        #output = response.choices[0].message.content + \"\\n\"\n",
    "        output = (response.choices[0].message.content).replace(\"```python\",\"\").replace(\"```\",\"\").strip()\n",
    "        create_tsql_file('load_bicycle_sales.sql', output)\n",
    "        print(output)\n",
    "    except Exception as ex:\n",
    "        print(ex)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this scenario, I’m adjusting ChatGPT’s settings for precision and conciseness by setting the temperature to zero. Additionally, I’m increasing the maximum token length to prevent the generated response from being truncated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "azure_openai_api_temperature = 0\n",
    "azure_openai_api_max_tokens  = 1000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this instance, I’m running the function that interacts with the Azure OpenAI API and subsequently storing the output in a file with a .sql extension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sending request for summary to Azure OpenAI endpoint...\n",
      "\n",
      "\n",
      "Here is the T-SQL script to import a CSV file from Azure Data Lake into a Synapse dedicated SQL pool:\n",
      "\n",
      "sql\n",
      "-- Drop objects if they exist\n",
      "IF EXISTS (SELECT * FROM sys.schemas WHERE name = 'stg')\n",
      "    DROP SCHEMA stg\n",
      "IF EXISTS (SELECT * FROM sys.schemas WHERE name = 'prd')\n",
      "    DROP SCHEMA prd\n",
      "IF EXISTS (SELECT * FROM sys.tables WHERE name = 'salestmp')\n",
      "    DROP TABLE stg.salestmp\n",
      "IF EXISTS (SELECT * FROM sys.tables WHERE name = 'sales')\n",
      "    DROP TABLE prd.sales\n",
      "IF EXISTS (SELECT * FROM sys.views WHERE name = 'vw_GetSaleDetails')\n",
      "    DROP VIEW prd.vw_GetSaleDetails\n",
      "\n",
      "-- Create staging and production schemas\n",
      "CREATE SCHEMA stg\n",
      "CREATE SCHEMA prd\n",
      "\n",
      "-- Create staging table\n",
      "CREATE TABLE stg.salestmp (\n",
      "    ProductId VARCHAR(255),\n",
      "    ProductName VARCHAR(255),\n",
      "    ProductType VARCHAR(255),\n",
      "    Color VARCHAR(255),\n",
      "    OrderQuantity VARCHAR(255),\n",
      "    Size VARCHAR(255),\n",
      "    Category VARCHAR(255),\n",
      "    Country VARCHAR(255),\n",
      "    Date VARCHAR(255),\n",
      "    PurchasePrice VARCHAR(255),\n",
      "    SellingPrice VARCHAR(255)\n",
      ")\n",
      "\n",
      "-- Create production table\n",
      "CREATE TABLE prd.sales (\n",
      "    ProductId INT,\n",
      "    ProductName VARCHAR(50),\n",
      "    ProductType VARCHAR(30),\n",
      "    Color VARCHAR(15),\n",
      "    OrderQuantity INT,\n",
      "    Size VARCHAR(15),\n",
      "    Category VARCHAR(15),\n",
      "    Country VARCHAR(30),\n",
      "    Date DATE,\n",
      "    PurchasePrice DECIMAL(18,2),\n",
      "    SellingPrice DECIMAL(18,2)\n",
      ")\n",
      "\n",
      "-- Load data from Azure Data Lake into staging table\n",
      "COPY INTO stg.salestmp\n",
      "(ProductId, ProductName, ProductType, Color, OrderQuantity, Size, Category, Country, Date, PurchasePrice, SellingPrice)\n",
      "FROM '<Azure Data Lake file path>'\n",
      "WITH (\n",
      "    FILE_TYPE = 'CSV',\n",
      "    FIELD_TERMINATOR = ',',\n",
      "    ROW_TERMINATOR = '\\n',\n",
      "    FIRST_ROW = 2,\n",
      "    CREDENTIAL=(IDENTITY ='Managed Identity')\n",
      ")\n",
      "\n",
      "-- Load data from staging table into production table\n",
      "INSERT INTO prd.sales\n",
      "SELECT\n",
      "    CAST(ProductId AS INT),\n",
      "    ProductName,\n",
      "    ProductType,\n",
      "    Color,\n",
      "    CAST(OrderQuantity AS INT),\n",
      "    Size,\n",
      "    Category,\n",
      "    Country,\n",
      "    CAST(Date AS DATE),\n",
      "    CAST(PurchasePrice AS DECIMAL(18,2)),\n",
      "    CAST(SellingPrice AS DECIMAL(18,2))\n",
      "FROM stg.salestmp\n",
      "\n",
      "-- Create view to return specific columns\n",
      "CREATE VIEW prd.vw_GetSaleDetails AS\n",
      "SELECT\n",
      "    Country,\n",
      "    ProductName,\n",
      "    ProductType,\n",
      "    Color,\n",
      "    Category,\n",
      "    Country\n",
      "FROM prd.sales\n",
      "\n",
      "-- Execute the view\n",
      "SELECT * FROM prd.vw_GetSaleDetails\n",
      "\n",
      "\n",
      "Make sure to replace `<Azure Data Lake file path>` with the actual path to your CSV file in Azure Data Lake.\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__': \n",
    "    SendRequestToAzureOpenAI (\n",
    "         azure_openai_api_type\n",
    "        ,azure_azur_openeai_endpoint\n",
    "        ,azure_openai_api_version\n",
    "        ,azure_azure_openeai_key\n",
    "        ,azure_openai_api_model\n",
    "        ,azure_openai_api_temperature\n",
    "        ,azure_openai_api_max_tokens\n",
    "        ,messages\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
