{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenization\n",
    "- Tokenization is a part of the preprocessing step before the input is fed into the encoder of a Large Language Model (LLM).\n",
    "\n",
    "- Tokenization is the process of splitting the input and output texts into smaller units or tokens that can be processed by the LLM AI models. \n",
    "    - Tokens can be words, characters, subwords, or symbols, depending on the type and the size of the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### install **tiktoken** if needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tiktoken in c:\\program files\\python311\\lib\\site-packages (0.5.1)\n",
      "Requirement already satisfied: regex>=2022.1.18 in c:\\program files\\python311\\lib\\site-packages (from tiktoken) (2023.10.3)\n",
      "Requirement already satisfied: requests>=2.26.0 in c:\\program files\\python311\\lib\\site-packages (from tiktoken) (2.31.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\program files\\python311\\lib\\site-packages (from requests>=2.26.0->tiktoken) (3.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\program files\\python311\\lib\\site-packages (from requests>=2.26.0->tiktoken) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\program files\\python311\\lib\\site-packages (from requests>=2.26.0->tiktoken) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\program files\\python311\\lib\\site-packages (from requests>=2.26.0->tiktoken) (2023.5.7)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.1.2 -> 23.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install --upgrade tiktoken"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Importing tiktoken, Load an Encoding & specify the model version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tiktoken\n",
    "# Load an encoding\n",
    "encoding = tiktoken.get_encoding(\"cl100k_base\")\n",
    "\n",
    "encoding = tiktoken.encoding_for_model(\"gpt-3.5-turbo\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Submit your prompts (input)\n",
    "- Tokenization\n",
    "    - Splitting the input text or prompts into tokens\n",
    "    - Vectorization (converting tokens into numerical vectors) -> Feeding into the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[b'What', b' is', b' Azure', b' Open', b'AI', b'?']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Splitting the input text or prompts into tokens\n",
    "\n",
    "# user input\n",
    "prompts = \"What is Azure OpenAI?\"\n",
    "\n",
    "response = encoding.encode(prompts)\n",
    "\n",
    "[encoding.decode_single_token_bytes(token) for token in response]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Maually verification\n",
    "- [Tokenizer](https://platform.openai.com/tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n"
     ]
    }
   ],
   "source": [
    "import tiktoken\n",
    "encoding = tiktoken.get_encoding(\"cl100k_base\")\n",
    "num_tokens = len(encoding.encode(prompts))\n",
    "print(num_tokens)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Turn text into tokens with encoding.encode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3923, 374, 35219, 5377, 15836, 30]\n"
     ]
    }
   ],
   "source": [
    "#Turn text into tokens with encoding.encode()\n",
    "prompts = \"What is Azure OpenAI?\"\n",
    "\n",
    "print(encoding.encode(prompts))\n",
    "\n",
    "#Turn tokens into text with encoding.decode()\n",
    "response = encoding.encode(prompts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Turn tokens into text with encoding.encode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'What is Azure OpenAI?'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoding.decode(response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
