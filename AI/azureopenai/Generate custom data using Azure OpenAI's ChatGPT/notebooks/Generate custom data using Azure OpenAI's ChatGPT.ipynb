{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate custom data using Azure OpenAI's ChatGPT\n",
    "> In this session, I will demonstrate the power of Azure OpenAI's ChatGPT in generating custom data. This capability is highly advantageous as it allows for the creation of personalized datasets, which can greatly enhance personal learning or enable effective class training.\n",
    "\n",
    "> Before we begin, there are a few considerations to keep in mind. To follow along with me, you will need to update the **config** file before executing notebook. In the **config file**, you should update the Azure OpenAI parameters for **azure_oai_endpoint**, **azure_oai_key**, **azure_oai_model**, **azure_openai_api_type**, and **azure_openai_api_version** along with **pd.read_csv(\"F:\\demos\\mttcommunity\\config.csv\")**. These parameters are necessary for the integration with Azure OpenAI services. Make sure to update the config file accordingly before proceeding."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How to use ChatGPT API parameters?\n",
    "In the below example, more parameters are added to openai.ChatCompletion.create() to generate a response. Here’s what each means:\n",
    "- The **engine** parameter specifies which language model to use (“text-davinci-002” is the most powerful GPT-3 model at the time of writing)\n",
    "- The **prompt** parameter is the text prompt to generate a response to\n",
    "- The **max_tokens** parameter sets the maximum number of tokens (words) that the model should generate\n",
    "- The **temperature** parameter controls the level of randomness in the generated text\n",
    "- The **stop** parameter can be used to specify one or more strings that should be used to indicate the end of the generated text\n",
    "- If you want to generate multiple responses, you can set **n** to the number of responses you want returned\n",
    "- The **strip()** method removes any leading and trailing spaces from the text."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Here, we are using the Python pandas library to read the config file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "az_openai_conf = pd.read_csv(\"F:\\demos\\mttcommunity\\config.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### In this part of the code, we are assigning the parameter values from the config file to specific variables. By assigning the parameter values, we can make use of them throughout the code for our integration with Azure OpenAI services."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add OpenAI import\n",
    "import openai\n",
    "\n",
    "# Set OpenAI configuration settings\n",
    "openai.api_type = az_openai_conf.azure_openai_api_type[0]\n",
    "openai.api_base = az_openai_conf.azure_oai_endpoint[0]\n",
    "openai.api_version = az_openai_conf.azure_openai_api_version[0]\n",
    "openai.api_key = az_openai_conf.azure_oai_key[0]\n",
    "\n",
    "\n",
    "azure_oai_model=az_openai_conf.azure_oai_model[0]\n",
    "azure_openai_api_temperature=0\n",
    "azure_openai_api_max_tokens=700"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This is optional as it will only return information about the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = openai.Model.list()\n",
    "print(models)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### In this part of the code, we are defining the context by assigning a role to the system. The context represents the specific role or perspective that the system assumes in a conversation or interaction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_context = \"You are a Data Engineer with expertise in Python. Your task is to create a sample dataset and use Python to load and analyze it.\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Here, we have the user input or prompts, which can be considered as requests or queries made by the user. These prompts are the statements or questions that the user wants the system or the AI model to respond to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_prompt = \"\"\"\n",
    "### Provide a 10 rows of sales history data file for bicycle accessories with details in the example format\n",
    "\n",
    "# This data file should contain sales history data for at least 10 bicycle accessories.\n",
    "\n",
    "Take this in consideration: \n",
    "order quantity (25-70) and prices (50-150 purchase, 125-400 selling). \n",
    "\n",
    "Example:\n",
    "ProductId,ProductName,ProductType,Color,OrderQuantity,Size,Category,Country,Date,PurchasePrice,SellingPrice\n",
    "001,Bike Lock,Accessory,Red,50,Large,Hydration,France,2023-01-01,59.78,128.98\n",
    "\n",
    "# Provide results in a tabular format.\n",
    "\n",
    "# dont provide any additional information\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### In this code snippet, we are using chatcompletion to generate a response from Azure OpenAI ChatGPT. We pass several parameters to guide the generation process:\n",
    "- **System and user roles:** We assign specific roles to the system and the user to define their positions and guide their interactions within the conversation.\n",
    "\n",
    "- **Azure OpenAI model:** We specify the Azure OpenAI model that will be used for generating the response. The model contains pre-trained knowledge and language understanding capabilities.\n",
    "\n",
    "- **Temperature:** The temperature parameter controls the randomness of the generated response. Higher values like 0.8 make the response more diverse and creative, while lower values like 0.2 make it more focused and deterministic.\n",
    "\n",
    "- **Max tokens:** This parameter sets the maximum length of the response generated by the model. It ensures that the response doesn't exceed a certain number of tokens or words.\n",
    "\n",
    "- **Prompts:** The prompts are the user's input or queries that we discussed earlier. They provide the context and information for generating the appropriate response.\n",
    "\n",
    "By providing these parameters to the chatcompletion function, we enable the Azure OpenAI ChatGPT model to generate a response based on the given prompts and the specified parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ProductId | ProductName | ProductType | Color | OrderQuantity | Size | Category | Country | Date | PurchasePrice | SellingPrice\n",
      "--- | --- | --- | --- | --- | --- | --- | --- | --- | --- | ---\n",
      "001 | Bike Lock | Accessory | Red | 50 | Large | Hydration | France | 2023-01-01 | 59.78 | 128.98\n",
      "002 | Bike Bell | Accessory | Blue | 30 | Medium | Safety | Germany | 2023-01-02 | 72.45 | 175.60\n",
      "003 | Bike Light | Accessory | Black | 45 | Small | Lighting | USA | 2023-01-03 | 89.99 | 225.00\n",
      "004 | Bike Pump | Accessory | Silver | 60 | Large | Inflation | Canada | 2023-01-04 | 120.00 | 350.00\n",
      "005 | Bike Helmet | Accessory | Yellow | 25 | Medium | Safety | Australia | 2023-01-05 | 99.99 | 199.99\n",
      "006 | Bike Basket | Accessory | Brown | 70 | Large | Storage | UK | 2023-01-06 | 55.00 | 150.00\n",
      "007 | Bike Gloves | Accessory | Green | 40 | Small | Apparel | France | 2023-01-07 | 45.99 | 99.99\n",
      "008 | Bike Water Bottle | Accessory | Pink | 55 | Medium | Hydration | USA | 2023-01-08 | 65.00 | 149.99\n",
      "009 | Bike Rack | Accessory | Grey | 65 | Large | Storage | Canada | 2023-01-09 | 150.00 | 399.99\n",
      "010 | Bike Mirror | Accessory | White | 35 | Small | Safety | Australia | 2023-01-10 | 55.00 | 129.99\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Build the messages array\n",
    "prompt =[\n",
    "    {\"role\": \"system\", \"content\": system_context},\n",
    "    {\"role\": \"user\", \"content\": user_prompt}\n",
    "]\n",
    "\n",
    "\n",
    "# Call the Azure OpenAI model\n",
    "response = openai.ChatCompletion.create(\n",
    "    engine=azure_oai_model,\n",
    "    temperature=azure_openai_api_temperature,\n",
    "    max_tokens=azure_openai_api_max_tokens,\n",
    "    messages=prompt\n",
    ")\n",
    "\n",
    "print('\\n' + response.choices[0].message.content + '\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this code snippet, we are modifying the prompt to generate a Python script for generating the Bicycle Accessories dataset. We provide examples of how the file should look, including the structure and format of the data.\n",
    "\n",
    "By modifying the prompt in this way, we instruct the code to generate a Python script that can create the Bicycle Accessories dataset according to the provided examples and save it to the specified location. This allows for the efficient generation and storage of the dataset for further use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_prompt = \"\"\"\n",
    "Write a Python pandas script that generates a sales history csv data file for bicycle accessories with details in the example format\n",
    "\n",
    "The file should contain 1000 rows of data in the {example} format, representing sales over a period of 5 years.\n",
    "\n",
    "Consideration: \n",
    "1. order quantity (25-70) and prices (50-150 purchase, 125-400 selling). Provide results in a tabular format.\n",
    "2. save the csv file to F:\\demos\\mttcommunity\\datafile\\sales_history.csv\n",
    "\n",
    "example:\n",
    "ProductId,ProductName,ProductType,Color,OrderQuantity,Size,Category,Country,Date,PurchasePrice,SellingPrice\n",
    "001,Bike Lock,Accessory,Red,50,Large,Hydration,France,2023-01-01,59.78,128.98\n",
    "\n",
    "# Provide results in a tabular format.\n",
    "\n",
    "# please do not provide any feedback before and after when providing the python script.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this code snippet, we define a Python function to enhance reusability and enable the saving of the generated dataset as a CSV file.\n",
    "\n",
    "By including this functionality within the function, we simplify the process of generating the dataset and automatically save it as a CSV file in the specified location. This makes it easier to manage and access the generated data for further analysis or usage in other applications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the messages array\n",
    "prompt =[\n",
    "    {\"role\": \"system\", \"content\": system_context},\n",
    "    {\"role\": \"user\", \"content\": user_prompt}\n",
    "]\n",
    "\n",
    "# define a function to generate the sales data\n",
    "def generate_bicycle_sales_data(\n",
    "     azure_oai_model\n",
    "    ,azure_openai_api_temperature\n",
    "    ,azure_openai_api_max_tokens\n",
    "    ,prompt \n",
    "):\n",
    "  try:\n",
    "    response = openai.ChatCompletion.create(\n",
    "        engine=azure_oai_model,\n",
    "        temperature=azure_openai_api_temperature,\n",
    "        max_tokens=azure_openai_api_max_tokens,\n",
    "        messages=prompt\n",
    "    )\n",
    "    # Create a global variable to store the response\n",
    "    global generate_sales_history_data\n",
    "    # Store the response in the global variable\n",
    "    generate_sales_history_data = (response.choices[0].message.content).replace(\"```python\",\"\").replace(\"```\",\"\").strip()\n",
    "    # execute the generated python script\n",
    "    exec(generate_sales_history_data)\n",
    "  except Exception as ex:\n",
    "    print(ex)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this part of the code, we execute the function that we defined previously. By calling the function with appropriate arguments, we trigger the execution of the code inside the function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ProductId  ProductName ProductType   Color  OrderQuantity    Size  \\\n",
      "0       002    Bike Pump   Accessory   Black             47   Large   \n",
      "1       004    Bike Bell   Accessory    Blue             65   Small   \n",
      "2       001    Bike Lock   Accessory    Blue             25   Large   \n",
      "3       003   Bike Light   Accessory  Yellow             67  Medium   \n",
      "4       005  Bike Helmet      Safety   Black             56   Large   \n",
      "\n",
      "    Category Country       Date  PurchasePrice  SellingPrice  \n",
      "0      Tools   Spain 2026-09-08         105.57        204.07  \n",
      "1      Bells   Italy 2023-10-27          50.63        159.32  \n",
      "2  Hydration      UK 2026-02-12          88.79        297.57  \n",
      "3     Lights   Spain 2026-11-14          83.38        392.76  \n",
      "4    Helmets      UK 2027-12-28          84.61        133.83  \n"
     ]
    }
   ],
   "source": [
    "generate_bicycle_sales_data(azure_oai_model,azure_openai_api_temperature,azure_openai_api_max_tokens,prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code is optional, but if you're interested, I can execute it to reveal the code generated by ChatGPT behind the scenes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "import pandas as pd\n",
      "import numpy as np\n",
      "import random\n",
      "from datetime import datetime, timedelta\n",
      "\n",
      "# Define product details\n",
      "product_ids = ['001', '002', '003', '004', '005']\n",
      "product_names = ['Bike Lock', 'Bike Pump', 'Bike Light', 'Bike Bell', 'Bike Helmet']\n",
      "product_types = ['Accessory', 'Accessory', 'Accessory', 'Accessory', 'Safety']\n",
      "colors = ['Red', 'Blue', 'Green', 'Yellow', 'Black']\n",
      "sizes = ['Small', 'Medium', 'Large']\n",
      "categories = ['Hydration', 'Tools', 'Lights', 'Bells', 'Helmets']\n",
      "countries = ['France', 'Germany', 'Spain', 'Italy', 'UK']\n",
      "\n",
      "# Define date range\n",
      "start_date = datetime(2023, 1, 1)\n",
      "end_date = datetime(2027, 12, 31)\n",
      "\n",
      "# Generate random sales data\n",
      "data = []\n",
      "for i in range(1000):\n",
      "    product_id = random.choice(product_ids)\n",
      "    product_name = product_names[product_ids.index(product_id)]\n",
      "    product_type = product_types[product_ids.index(product_id)]\n",
      "    color = random.choice(colors)\n",
      "    order_quantity = random.randint(25, 70)\n",
      "    size = random.choice(sizes)\n",
      "    category = categories[product_ids.index(product_id)]\n",
      "    country = random.choice(countries)\n",
      "    date = start_date + timedelta(days=random.randint(0, (end_date - start_date).days))\n",
      "    purchase_price = round(random.uniform(50, 150), 2)\n",
      "    selling_price = round(random.uniform(125, 400), 2)\n",
      "    data.append([product_id, product_name, product_type, color, order_quantity, size, category, country, date, purchase_price, selling_price])\n",
      "\n",
      "# Create pandas dataframe and save to csv\n",
      "df = pd.DataFrame(data, columns=['ProductId', 'ProductName', 'ProductType', 'Color', 'OrderQuantity', 'Size', 'Category', 'Country', 'Date', 'PurchasePrice', 'SellingPrice'])\n",
      "df.to_csv('F:/demos/mttcommunity/datafile/sales_history.csv', index=False)\n",
      "\n",
      "# Display sample data\n",
      "print(df.head())\n"
     ]
    }
   ],
   "source": [
    "print(generate_sales_history_data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
